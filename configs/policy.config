# policy configurations for robot

[rl]
gamma = 0.9


[om]
cell_num = 4
cell_size = 1
om_channel_size = 3


[action_space]
kinematics = holonomic
# action space size is speed_samples * rotation_samples + 1
speed_samples = 4
rotation_samples = 8
sampling = exponential
query_env = true


[cadrl]
mlp_dims = 150, 100, 100, 1
multiagent_training = true


[lstm_rl]
global_state_dim = 50
mlp_dims = 256, 256, 1
multiagent_training = true
with_om = false
with_interaction_module = false


[sarl]
mlp1_dims = 150, 100
mlp2_dims = 100, 50
attention_dims = 100, 100, 1
mlp3_dims = 150, 100, 100, 1
multiagent_training = true
with_om = false
with_global_state = true


[esa]
# lstm module
hn_state_dim = 50
mlp11_dims = 256, 128, 64
# lstm排序权重
current_dist_weight = 0.8
# sarl模块
mlp21_dims = 128, 64
mlp23_dims = 100, 100
attention_dims = 64, 64, 1
with_global_state = true
# 共有
multiagent_training = true
with_om = false
mlp_final = 128, 64, 1

[esa2]
# lstm module
hn_state_dim = 50
mlp11_dims = 256, 128, 64
# lstm排序权重
current_dist_weight = 0.8
# sarl模块
mlp21_dims = 128, 64
mlp23_dims = 64, 64
attention_dims = 64, 64, 1
with_global_state = false
# 共有
multiagent_training = true
with_om = false
mlp_final = 128, 100

[esa_recurrent2]
# lstm module
hn_state_dim = 50
mlp11_dims = 256, 128, 64
# lstm排序权重
current_dist_weight = 0.8
# sarl模块
mlp21_dims = 128, 64
mlp23_dims = 64, 64
attention_dims = 64, 64, 1
with_global_state = false
# 共有
multiagent_training = true
with_om = false
mlp_final = 128, 100
t_hn_state_dim = 100

[sarl2]
mlp1_dims = 150, 100
mlp2_dims = 100, 50
attention_dims = 100, 100, 1
mlp3_dims = 150, 100, 100
multiagent_training = true
with_om = false
with_global_state = true

[lstm_rl2]
hn_state_dim = 50
mlp_dims = 256, 256
